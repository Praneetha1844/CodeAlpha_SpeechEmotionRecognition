{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhKRewmraOTZh3U+F+jqG8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"0FQY75NGgYmr","executionInfo":{"status":"ok","timestamp":1701789219746,"user_tz":-330,"elapsed":1342,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}}},"outputs":[],"source":["import librosa\n","import soundfile\n","import os, glob, pickle\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","source":["def extract_feature(file_name, mfcc, chroma, mel):\n","    with soundfile.SoundFile(file_name) as sound_file:\n","        X = sound_file.read(dtype=\"float32\")\n","        sample_rate = sound_file.samplerate\n","        if chroma:\n","            stft = np.abs(librosa.stft(X))\n","        result = np.array([])\n","        if mfcc:\n","            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","            result = np.hstack((result, mfccs))\n","        if chroma:\n","            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n","            result = np.hstack((result, chroma))\n","        if mel:\n","            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n","            result = np.hstack((result, mel))\n","    return result\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"tomkO9KEilpG","executionInfo":{"status":"ok","timestamp":1701789325064,"user_tz":-330,"elapsed":457,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Emotions in the RAVDESS dataset\n","emotions={\n","  '01':'neutral',\n","  '02':'calm',\n","  '03':'happy',\n","  '04':'sad',\n","  '05':'angry',\n","  '06':'fearful',\n","  '07':'disgust',\n","  '08':'surprised'\n","}\n","\n","#DataFlair - Emotions to observe\n","observed_emotions=['calm', 'happy', 'fearful', 'disgust']"],"metadata":{"id":"RNMloH_Piwce","executionInfo":{"status":"ok","timestamp":1701790069408,"user_tz":-330,"elapsed":4,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Load the data and extract features for each sound file\n","def load_data(test_size=0.2):\n","    x,y=[],[]\n","    for file in glob.glob(\"D:\\\\DataFlair\\\\ravdess data\\\\Actor_*\\\\*.wav\"):\n","        file_name=os.path.basename(file)\n","        emotion=emotions[file_name.split(\"-\")[2]]\n","        if emotion not in observed_emotions:\n","            continue\n","        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n","        x.append(feature)\n","        y.append(emotion)\n","    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"],"metadata":{"id":"aq6JmZjzjIbc","executionInfo":{"status":"ok","timestamp":1701789815438,"user_tz":-330,"elapsed":4,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Split the dataset\n","x_train,x_test,y_train,y_test=load_data(test_size=0.25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":314},"id":"_tWLxknAkrfB","executionInfo":{"status":"error","timestamp":1701790406250,"user_tz":-330,"elapsed":69,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}},"outputId":"c28f545b-06bd-43ef-fd7b-5fdd54da2aa8"},"execution_count":14,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-19a3db7bb0fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#DataFlair - Split the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-0f76b3571ab5>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(test_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"//content//speech-emotion-recognition-ravdess-data.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memotions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobserved_emotions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'recognition'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xohorA5ulBt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Load the data and extract features for each sound file\n","def load_data(test_size=0.2):\n","    x,y=[],[]\n","    for file in glob.glob(\"//content//speech-emotion-recognition-ravdess-data.zip\"):\n","        file_name=os.path.basename(file)\n","        emotion=emotions[file_name.split(\"-\")[2]]\n","        if emotion not in observed_emotions:\n","            continue\n","        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n","        x.append(feature)\n","        y.append(emotion)\n","    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"],"metadata":{"id":"tTp5xSsMlHGu","executionInfo":{"status":"ok","timestamp":1701790332722,"user_tz":-330,"elapsed":4,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Get the number of features extracted\n","print(f'Features extracted: {x_train.shape[1]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"1_HzIuwTlSdm","executionInfo":{"status":"error","timestamp":1701790350208,"user_tz":-330,"elapsed":79,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}},"outputId":"073f01d1-487c-46bb-e33b-ac89ec061de3"},"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-44053be2d641>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#DataFlair - Get the number of features extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Features extracted: {x_train.shape[1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"]}]},{"cell_type":"code","source":["#DataFlair - Get the shape of the training and testing datasets\n","print((x_train.shape[0], x_test.shape[0]))"],"metadata":{"id":"mYSyVhJwlYcX","executionInfo":{"status":"aborted","timestamp":1701789939685,"user_tz":-330,"elapsed":186,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Get the number of features extracted\n","print(f'Features extracted: {x_train.shape[1]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"id":"d_O-DFZwlaW6","executionInfo":{"status":"error","timestamp":1701790264302,"user_tz":-330,"elapsed":135,"user":{"displayName":"Praneetha Potharaju","userId":"04586156684512447649"}},"outputId":"cc8463e5-29af-4ec6-df3c-b47ba8875c09"},"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-44053be2d641>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#DataFlair - Get the number of features extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Features extracted: {x_train.shape[1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"]}]},{"cell_type":"code","source":["#DataFlair - Initialize the Multi Layer Perceptron Classifier\n","model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"],"metadata":{"id":"JXhJkC59mkp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Train the model\n","model.fit(x_train,y_train)"],"metadata":{"id":"u1V8zK9qmpCo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Predict for the test set\n","y_pred=model.predict(x_test)"],"metadata":{"id":"6mzHv52rmp_z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DataFlair - Calculate the accuracy of our model\n","accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n","\n","#DataFlair - Print the accuracy\n","print(\"Accuracy: {:.2f}%\".format(accuracy*100))"],"metadata":{"id":"x3_9XrC6msd2"},"execution_count":null,"outputs":[]}]}